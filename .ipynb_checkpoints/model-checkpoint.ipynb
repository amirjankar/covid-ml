{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Machine Learning Regression Models on Predicting Coronavirus Spread\n",
    "\n",
    "Anish Mirjankar, 5/5/2020\n",
    "\n",
    "The 2019 spread of Coronavirus, or COVID-19, is considered one of the largest pandemics in decades.  Data is being collected by local, state, and federal government agencies across the country, as well as countless private organizations, tracking testing and cases as they develop around the country.  I chose to use data from the COVID Tracking Project, an organization which maintains an api of all current and historical cases collected from the entire country.  \n",
    "\n",
    "Some questions that I am looking to answer are:\n",
    "\n",
    "1. Does this data suffice to train a model that can successfully predict the spread of COVID in an area given the historical data provided?\n",
    "2. Can we predict the number of total cases in a given region based on the testing/hospitalization data, state information, and any other categorical parameters included?\n",
    "3. Can this model predict certain outcomes based on the pre-processed, daily intake data provided by the API?\n",
    "4. Which method of machine learning can generate the most succesful prediction/model of the coronavirus spread?\n",
    "\n",
    "Data sources:\n",
    "\n",
    "* [the COVID tracking Project](https://covidtracking.com)\n",
    "* [United States Census](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>...</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>fips</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200505</td>\n",
       "      <td>AK</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22692</td>\n",
       "      <td>22692</td>\n",
       "      <td>22692</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200505</td>\n",
       "      <td>AL</td>\n",
       "      <td>8285.0</td>\n",
       "      <td>98481.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>428.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>106766</td>\n",
       "      <td>106766</td>\n",
       "      <td>106766</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200505</td>\n",
       "      <td>AR</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>51139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>453.0</td>\n",
       "      <td>54635</td>\n",
       "      <td>54635</td>\n",
       "      <td>54635</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200505</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200505</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9305.0</td>\n",
       "      <td>78955.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>88260</td>\n",
       "      <td>88260</td>\n",
       "      <td>88260</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>3007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>20200126</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>20200125</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>20200124</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>20200123</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>20200122</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3433 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date state  positive  negative  pending  hospitalizedCurrently  \\\n",
       "0     20200505    AK     371.0   22321.0      NaN                   13.0   \n",
       "1     20200505    AL    8285.0   98481.0      NaN                    NaN   \n",
       "2     20200505    AR    3496.0   51139.0      NaN                   89.0   \n",
       "3     20200505    AS       0.0      83.0      NaN                    NaN   \n",
       "4     20200505    AZ    9305.0   78955.0      NaN                  728.0   \n",
       "...        ...   ...       ...       ...      ...                    ...   \n",
       "3428  20200126    WA       1.0       NaN      NaN                    NaN   \n",
       "3429  20200125    WA       1.0       NaN      NaN                    NaN   \n",
       "3430  20200124    WA       1.0       NaN      NaN                    NaN   \n",
       "3431  20200123    WA       1.0       NaN      NaN                    NaN   \n",
       "3432  20200122    WA       1.0       NaN      NaN                    NaN   \n",
       "\n",
       "      hospitalizedCumulative  inIcuCurrently  inIcuCumulative  \\\n",
       "0                        NaN             NaN              NaN   \n",
       "1                     1107.0             NaN            428.0   \n",
       "2                      453.0             NaN              NaN   \n",
       "3                        NaN             NaN              NaN   \n",
       "4                     1397.0           303.0              NaN   \n",
       "...                      ...             ...              ...   \n",
       "3428                     NaN             NaN              NaN   \n",
       "3429                     NaN             NaN              NaN   \n",
       "3430                     NaN             NaN              NaN   \n",
       "3431                     NaN             NaN              NaN   \n",
       "3432                     NaN             NaN              NaN   \n",
       "\n",
       "      onVentilatorCurrently  ...  hospitalized   total totalTestResults  \\\n",
       "0                       NaN  ...           NaN   22692            22692   \n",
       "1                       NaN  ...        1107.0  106766           106766   \n",
       "2                      16.0  ...         453.0   54635            54635   \n",
       "3                       NaN  ...           NaN      83               83   \n",
       "4                     185.0  ...        1397.0   88260            88260   \n",
       "...                     ...  ...           ...     ...              ...   \n",
       "3428                    NaN  ...           NaN       1                1   \n",
       "3429                    NaN  ...           NaN       1                1   \n",
       "3430                    NaN  ...           NaN       1                1   \n",
       "3431                    NaN  ...           NaN       1                1   \n",
       "3432                    NaN  ...           NaN       1                1   \n",
       "\n",
       "      posNeg fips deathIncrease  hospitalizedIncrease  negativeIncrease  \\\n",
       "0      22692    2           0.0                   0.0             968.0   \n",
       "1     106766    1          17.0                  43.0            3389.0   \n",
       "2      54635    5          -1.0                  15.0             155.0   \n",
       "3         83   60           0.0                   0.0               0.0   \n",
       "4      88260    4          33.0                  40.0            2621.0   \n",
       "...      ...  ...           ...                   ...               ...   \n",
       "3428       1   53           0.0                   0.0               0.0   \n",
       "3429       1   53           0.0                   0.0               0.0   \n",
       "3430       1   53           0.0                   0.0               0.0   \n",
       "3431       1   53           0.0                   0.0               0.0   \n",
       "3432       1   53           NaN                   NaN               NaN   \n",
       "\n",
       "      positiveIncrease  totalTestResultsIncrease  \n",
       "0                  1.0                     969.0  \n",
       "1                260.0                    3649.0  \n",
       "2                 38.0                     193.0  \n",
       "3                  0.0                       0.0  \n",
       "4                386.0                    3007.0  \n",
       "...                ...                       ...  \n",
       "3428               0.0                       0.0  \n",
       "3429               0.0                       0.0  \n",
       "3430               0.0                       0.0  \n",
       "3431               0.0                       0.0  \n",
       "3432               NaN                       NaN  \n",
       "\n",
       "[3433 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "links = {\n",
    "    'curr_state': 'https://covidtracking.com/api/v1/states/current.csv',\n",
    "    'hist_state': 'https://covidtracking.com/api/v1/states/daily.csv',\n",
    "    'state_info': 'https://covidtracking.com/api/v1/states/info.csv',\n",
    "    'curr_us': 'https://covidtracking.com/api/v1/us/current.csv',\n",
    "    'hist_us': 'https://covidtracking.com/api/v1/us/daily.csv',\n",
    "    'tracker': 'https://covidtracking.com/api/v1/urls.csv',\n",
    "    'state_pages': 'https://covidtracking.com/api/v1/states/screenshots.csv',\n",
    "    'state_pop':'https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv'\n",
    "}\n",
    "\n",
    "df_hist = pd.read_csv(links['hist_state'])\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Pre-Processing\n",
    "\n",
    "The data provided requires cleanup and pre-processing to be suitable for intake by a regression model. First, all categorical fields must either be dumped or converted to a integer/float.  \n",
    "\n",
    "### Adding population data\n",
    "This specific dataset highly requires differentiation between states, therefore the state name is converted to its index in a static list of states and their population data.  The two dataframes are joined to provide each region with its associated states population data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2019</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "      <th>RNETMIG2016</th>\n",
       "      <th>RNETMIG2017</th>\n",
       "      <th>RNETMIG2018</th>\n",
       "      <th>RNETMIG2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200505</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.929847</td>\n",
       "      <td>0.587728</td>\n",
       "      <td>1.416798</td>\n",
       "      <td>-0.955359</td>\n",
       "      <td>-11.460949</td>\n",
       "      <td>-7.997118</td>\n",
       "      <td>-3.897349</td>\n",
       "      <td>-10.992765</td>\n",
       "      <td>-13.859140</td>\n",
       "      <td>-12.031221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200505</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.600119</td>\n",
       "      <td>24.591440</td>\n",
       "      <td>7.324889</td>\n",
       "      <td>12.053639</td>\n",
       "      <td>-2.690985</td>\n",
       "      <td>6.846257</td>\n",
       "      <td>-4.156770</td>\n",
       "      <td>26.400704</td>\n",
       "      <td>-20.729927</td>\n",
       "      <td>-17.825312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200505</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.143339</td>\n",
       "      <td>-0.538551</td>\n",
       "      <td>14.389767</td>\n",
       "      <td>13.097005</td>\n",
       "      <td>3.793430</td>\n",
       "      <td>-9.997414</td>\n",
       "      <td>-16.541877</td>\n",
       "      <td>1.399335</td>\n",
       "      <td>-20.582285</td>\n",
       "      <td>-6.741174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200505</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.188659</td>\n",
       "      <td>-1.387574</td>\n",
       "      <td>-3.485563</td>\n",
       "      <td>-0.647317</td>\n",
       "      <td>-15.024083</td>\n",
       "      <td>-18.026915</td>\n",
       "      <td>-10.615404</td>\n",
       "      <td>-18.607576</td>\n",
       "      <td>-20.702426</td>\n",
       "      <td>-15.930277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200505</td>\n",
       "      <td>371.0</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.808086</td>\n",
       "      <td>-1.507115</td>\n",
       "      <td>-3.307199</td>\n",
       "      <td>-8.955728</td>\n",
       "      <td>-15.032972</td>\n",
       "      <td>-15.491349</td>\n",
       "      <td>-13.786586</td>\n",
       "      <td>-12.128932</td>\n",
       "      <td>-7.326007</td>\n",
       "      <td>-4.698812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198955</th>\n",
       "      <td>20200122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.645400</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>8.008008</td>\n",
       "      <td>11.202390</td>\n",
       "      <td>6.933267</td>\n",
       "      <td>1.735681</td>\n",
       "      <td>41.300098</td>\n",
       "      <td>26.153115</td>\n",
       "      <td>37.387491</td>\n",
       "      <td>19.543974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198956</th>\n",
       "      <td>20200122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.109166</td>\n",
       "      <td>6.049392</td>\n",
       "      <td>-4.832748</td>\n",
       "      <td>-1.297498</td>\n",
       "      <td>0.740298</td>\n",
       "      <td>5.776862</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>7.915699</td>\n",
       "      <td>1.370462</td>\n",
       "      <td>1.861998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198957</th>\n",
       "      <td>20200122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.585832</td>\n",
       "      <td>5.392127</td>\n",
       "      <td>3.041486</td>\n",
       "      <td>2.662215</td>\n",
       "      <td>6.836831</td>\n",
       "      <td>13.619372</td>\n",
       "      <td>18.208863</td>\n",
       "      <td>20.473840</td>\n",
       "      <td>14.540748</td>\n",
       "      <td>15.359428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198958</th>\n",
       "      <td>20200122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.425166</td>\n",
       "      <td>1.357788</td>\n",
       "      <td>29.032927</td>\n",
       "      <td>-1.798234</td>\n",
       "      <td>-0.789670</td>\n",
       "      <td>22.317579</td>\n",
       "      <td>10.186827</td>\n",
       "      <td>8.451622</td>\n",
       "      <td>3.856054</td>\n",
       "      <td>5.451612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198959</th>\n",
       "      <td>20200122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.798229</td>\n",
       "      <td>-3.349776</td>\n",
       "      <td>-8.596635</td>\n",
       "      <td>-7.409483</td>\n",
       "      <td>-7.414539</td>\n",
       "      <td>-4.920452</td>\n",
       "      <td>-1.886842</td>\n",
       "      <td>-4.795202</td>\n",
       "      <td>-3.876248</td>\n",
       "      <td>-5.344661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198705 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  positive  negative  pending  hospitalizedCurrently  \\\n",
       "0       20200505     371.0   22321.0      NaN                   13.0   \n",
       "1       20200505     371.0   22321.0      NaN                   13.0   \n",
       "2       20200505     371.0   22321.0      NaN                   13.0   \n",
       "3       20200505     371.0   22321.0      NaN                   13.0   \n",
       "4       20200505     371.0   22321.0      NaN                   13.0   \n",
       "...          ...       ...       ...      ...                    ...   \n",
       "198955  20200122       1.0       NaN      NaN                    NaN   \n",
       "198956  20200122       1.0       NaN      NaN                    NaN   \n",
       "198957  20200122       1.0       NaN      NaN                    NaN   \n",
       "198958  20200122       1.0       NaN      NaN                    NaN   \n",
       "198959  20200122       1.0       NaN      NaN                    NaN   \n",
       "\n",
       "        hospitalizedCumulative  inIcuCurrently  inIcuCumulative  \\\n",
       "0                          NaN             NaN              NaN   \n",
       "1                          NaN             NaN              NaN   \n",
       "2                          NaN             NaN              NaN   \n",
       "3                          NaN             NaN              NaN   \n",
       "4                          NaN             NaN              NaN   \n",
       "...                        ...             ...              ...   \n",
       "198955                     NaN             NaN              NaN   \n",
       "198956                     NaN             NaN              NaN   \n",
       "198957                     NaN             NaN              NaN   \n",
       "198958                     NaN             NaN              NaN   \n",
       "198959                     NaN             NaN              NaN   \n",
       "\n",
       "        onVentilatorCurrently  onVentilatorCumulative  ...  RDOMESTICMIG2019  \\\n",
       "0                         NaN                     NaN  ...        -12.929847   \n",
       "1                         NaN                     NaN  ...        -30.600119   \n",
       "2                         NaN                     NaN  ...        -16.143339   \n",
       "3                         NaN                     NaN  ...        -17.188659   \n",
       "4                         NaN                     NaN  ...         -4.808086   \n",
       "...                       ...                     ...  ...               ...   \n",
       "198955                    NaN                     NaN  ...         18.645400   \n",
       "198956                    NaN                     NaN  ...          2.109166   \n",
       "198957                    NaN                     NaN  ...         13.585832   \n",
       "198958                    NaN                     NaN  ...         -2.425166   \n",
       "198959                    NaN                     NaN  ...         -4.798229   \n",
       "\n",
       "        RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \\\n",
       "0          0.587728     1.416798    -0.955359   -11.460949    -7.997118   \n",
       "1         24.591440     7.324889    12.053639    -2.690985     6.846257   \n",
       "2         -0.538551    14.389767    13.097005     3.793430    -9.997414   \n",
       "3         -1.387574    -3.485563    -0.647317   -15.024083   -18.026915   \n",
       "4         -1.507115    -3.307199    -8.955728   -15.032972   -15.491349   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "198955     7.272727     8.008008    11.202390     6.933267     1.735681   \n",
       "198956     6.049392    -4.832748    -1.297498     0.740298     5.776862   \n",
       "198957     5.392127     3.041486     2.662215     6.836831    13.619372   \n",
       "198958     1.357788    29.032927    -1.798234    -0.789670    22.317579   \n",
       "198959    -3.349776    -8.596635    -7.409483    -7.414539    -4.920452   \n",
       "\n",
       "        RNETMIG2016  RNETMIG2017  RNETMIG2018  RNETMIG2019  \n",
       "0         -3.897349   -10.992765   -13.859140   -12.031221  \n",
       "1         -4.156770    26.400704   -20.729927   -17.825312  \n",
       "2        -16.541877     1.399335   -20.582285    -6.741174  \n",
       "3        -10.615404   -18.607576   -20.702426   -15.930277  \n",
       "4        -13.786586   -12.128932    -7.326007    -4.698812  \n",
       "...             ...          ...          ...          ...  \n",
       "198955    41.300098    26.153115    37.387491    19.543974  \n",
       "198956     0.133400     7.915699     1.370462     1.861998  \n",
       "198957    18.208863    20.473840    14.540748    15.359428  \n",
       "198958    10.186827     8.451622     3.856054     5.451612  \n",
       "198959    -1.886842    -4.795202    -3.876248    -5.344661  \n",
       "\n",
       "[198705 rows x 184 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_df(old):\n",
    "    states_to_abb = {\"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\", \n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\",     \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \n",
    "    \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \n",
    "    \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \n",
    "    \"Ohio\": \"OH\", \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\", \n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\", \"District of Columbia\": \"DC\"}\n",
    "\n",
    "    df_states = pd.read_csv(links['state_pop'], encoding=\"latin-1\")\n",
    "    df_states[\"statecode\"] = df_states['STNAME'].apply(lambda x: states_to_abb[x])\n",
    "\n",
    "    df = pd.merge(old, df_states, left_on=\"state\", right_on=\"statecode\", how=\"left\")\n",
    "    df = df[df['statecode'].notna()]\n",
    "    cols_to_retain = [k for k,v in df.dtypes.to_dict().items() if v in [np.float64, np.int64]]\n",
    "    # cleanup non-numerical columns\n",
    "    df = df[cols_to_retain]\n",
    "    return df\n",
    "df = generate_df(df_hist)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'positive', 'negative', 'pending', 'hospitalizedCurrently', 'hospitalizedCumulative', 'inIcuCurrently', 'inIcuCumulative', 'onVentilatorCurrently', 'onVentilatorCumulative', 'recovered', 'death', 'hospitalized', 'total', 'totalTestResults', 'posNeg', 'fips', 'deathIncrease', 'hospitalizedIncrease', 'negativeIncrease', 'positiveIncrease', 'totalTestResultsIncrease', 'SUMLEV', 'REGION', 'DIVISION', 'STATE', 'COUNTY', 'CENSUS2010POP', 'ESTIMATESBASE2010', 'POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013', 'POPESTIMATE2014', 'POPESTIMATE2015', 'POPESTIMATE2016', 'POPESTIMATE2017', 'POPESTIMATE2018', 'POPESTIMATE2019', 'NPOPCHG_2010', 'NPOPCHG_2011', 'NPOPCHG_2012', 'NPOPCHG_2013', 'NPOPCHG_2014', 'NPOPCHG_2015', 'NPOPCHG_2016', 'NPOPCHG_2017', 'NPOPCHG_2018', 'NPOPCHG_2019', 'BIRTHS2010', 'BIRTHS2011', 'BIRTHS2012', 'BIRTHS2013', 'BIRTHS2014', 'BIRTHS2015', 'BIRTHS2016', 'BIRTHS2017', 'BIRTHS2018', 'BIRTHS2019', 'DEATHS2010', 'DEATHS2011', 'DEATHS2012', 'DEATHS2013', 'DEATHS2014', 'DEATHS2015', 'DEATHS2016', 'DEATHS2017', 'DEATHS2018', 'DEATHS2019', 'NATURALINC2010', 'NATURALINC2011', 'NATURALINC2012', 'NATURALINC2013', 'NATURALINC2014', 'NATURALINC2015', 'NATURALINC2016', 'NATURALINC2017', 'NATURALINC2018', 'NATURALINC2019', 'INTERNATIONALMIG2010', 'INTERNATIONALMIG2011', 'INTERNATIONALMIG2012', 'INTERNATIONALMIG2013', 'INTERNATIONALMIG2014', 'INTERNATIONALMIG2015', 'INTERNATIONALMIG2016', 'INTERNATIONALMIG2017', 'INTERNATIONALMIG2018', 'INTERNATIONALMIG2019', 'DOMESTICMIG2010', 'DOMESTICMIG2011', 'DOMESTICMIG2012', 'DOMESTICMIG2013', 'DOMESTICMIG2014', 'DOMESTICMIG2015', 'DOMESTICMIG2016', 'DOMESTICMIG2017', 'DOMESTICMIG2018', 'DOMESTICMIG2019', 'NETMIG2010', 'NETMIG2011', 'NETMIG2012', 'NETMIG2013', 'NETMIG2014', 'NETMIG2015', 'NETMIG2016', 'NETMIG2017', 'NETMIG2018', 'NETMIG2019', 'RESIDUAL2010', 'RESIDUAL2011', 'RESIDUAL2012', 'RESIDUAL2013', 'RESIDUAL2014', 'RESIDUAL2015', 'RESIDUAL2016', 'RESIDUAL2017', 'RESIDUAL2018', 'RESIDUAL2019', 'GQESTIMATESBASE2010', 'GQESTIMATES2010', 'GQESTIMATES2011', 'GQESTIMATES2012', 'GQESTIMATES2013', 'GQESTIMATES2014', 'GQESTIMATES2015', 'GQESTIMATES2016', 'GQESTIMATES2017', 'GQESTIMATES2018', 'GQESTIMATES2019', 'RBIRTH2011', 'RBIRTH2012', 'RBIRTH2013', 'RBIRTH2014', 'RBIRTH2015', 'RBIRTH2016', 'RBIRTH2017', 'RBIRTH2018', 'RBIRTH2019', 'RDEATH2011', 'RDEATH2012', 'RDEATH2013', 'RDEATH2014', 'RDEATH2015', 'RDEATH2016', 'RDEATH2017', 'RDEATH2018', 'RDEATH2019', 'RNATURALINC2011', 'RNATURALINC2012', 'RNATURALINC2013', 'RNATURALINC2014', 'RNATURALINC2015', 'RNATURALINC2016', 'RNATURALINC2017', 'RNATURALINC2018', 'RNATURALINC2019', 'RINTERNATIONALMIG2011', 'RINTERNATIONALMIG2012', 'RINTERNATIONALMIG2013', 'RINTERNATIONALMIG2014', 'RINTERNATIONALMIG2015', 'RINTERNATIONALMIG2016', 'RINTERNATIONALMIG2017', 'RINTERNATIONALMIG2018', 'RINTERNATIONALMIG2019', 'RDOMESTICMIG2011', 'RDOMESTICMIG2012', 'RDOMESTICMIG2013', 'RDOMESTICMIG2014', 'RDOMESTICMIG2015', 'RDOMESTICMIG2016', 'RDOMESTICMIG2017', 'RDOMESTICMIG2018', 'RDOMESTICMIG2019', 'RNETMIG2011', 'RNETMIG2012', 'RNETMIG2013', 'RNETMIG2014', 'RNETMIG2015', 'RNETMIG2016', 'RNETMIG2017', 'RNETMIG2018', 'RNETMIG2019']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "The following n-fold cross validation function is used to accurately train and test each algorithm and its validity.  It will be used to compare the algorithm on a subset of metrics, including MAE, MSE, and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "def n_fold_cross_validation(dataset, class_name, n_splits=5, metrics={}, **kwargs):\n",
    "    \"\"\"\n",
    "    dataset = dataset to split\n",
    "    class_name = results class column name\n",
    "    n_splits = number of splits to use\n",
    "    metrics = list of metrics to include\n",
    "    kwargs = dict of estimators to use (pass as name=MLClass)\n",
    "    \"\"\"\n",
    "    results = {k:{m:0 for m, _ in metrics.items()} for k, _ in kwargs.items()}\n",
    "    split_data = np.array_split(dataset.sample(frac=1), n_splits)\n",
    "    print(results)\n",
    "    for i, testing in enumerate(split_data):        \n",
    "        print(f\"\\nIteration {i+1}: \")\n",
    "        # creating tr_attributes, tr_class, te_attributes, te_class = training and testing frames\n",
    "        training = pd.concat([df for j, df in enumerate(split_data) if j != i])\n",
    "\n",
    "        # fill unknown results - mean for numerical data and most frequent for categorical data\n",
    "        training = training.fillna(training.mean())\n",
    "        testing = testing.fillna(testing.mean())\n",
    "\n",
    "        tr_attributes, tr_class = training.drop(columns=class_name).to_numpy(), training[class_name].to_numpy()\n",
    "        te_attributes, te_class = testing.drop(columns=class_name).to_numpy(), testing[class_name].to_numpy()\n",
    "        \n",
    "        for j, (name, model) in enumerate(kwargs.items()):\n",
    "            start_time = dt.datetime.now()\n",
    "            model = model.fit(tr_attributes, tr_class)\n",
    "            tr_time = dt.datetime.now()\n",
    "            \n",
    "            # for seeing the results in original dataset\n",
    "            #testing[\"prediction\"] = model.predict(te_attributes)\n",
    "            #print(testing)\n",
    "            \n",
    "            for k, func in metrics.items():\n",
    "                results[name][k] += func(model.predict(te_attributes), te_class)\n",
    "            end_time = dt.datetime.now()\n",
    "            print(f\"Training time for {name}: {tr_time-start_time}s \\nTesting time for {name}: {end_time-tr_time}s\")\n",
    "        \n",
    "    # divide summed metrics by number of splits to find final average\n",
    "    for k, v  in results.items():\n",
    "        results[k] = {met_name:met_data/n_splits for met_name, met_data in v.items()}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "In order to properly tune each model for the use case at hand, the below implementations were created.  All models can then be compared by their results from the n-fold cross validation function above.  The following regression models were selected due to their individual characteristics:\n",
    "\n",
    "* Linear Regression Model\n",
    "* Decision Tree Regressor\n",
    "* MLP Regressor\n",
    "* Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lin': {'mae': 0, 'mse': 0, 'rmse': 0}, 'dtree': {'mae': 0, 'mse': 0, 'rmse': 0}}\n",
      "\n",
      "Iteration 1: \n",
      "Training time for lin: 0:00:03.041407s \n",
      "Testing time for lin: 0:00:00.056997s\n",
      "Training time for dtree: 0:00:21.818264s \n",
      "Testing time for dtree: 0:00:00.132025s\n",
      "\n",
      "Iteration 2: \n",
      "Training time for lin: 0:00:02.814696s \n",
      "Testing time for lin: 0:00:00.048519s\n",
      "Training time for dtree: 0:00:22.342130s \n",
      "Testing time for dtree: 0:00:00.146007s\n",
      "\n",
      "Iteration 3: \n",
      "Training time for lin: 0:00:02.955501s \n",
      "Testing time for lin: 0:00:00.059063s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "\n",
    "linear = LinearRegression()\n",
    "dtree = DecisionTreeRegressor()\n",
    "mlp = MLPRegressor()\n",
    "svm = SVR()\n",
    "\n",
    "results = n_fold_cross_validation(\n",
    "    df,\n",
    "    metrics={\n",
    "        'mae':metrics.mean_absolute_error, \n",
    "        'mse':metrics.mean_squared_error, \n",
    "        'rmse': lambda x,y: np.sqrt(metrics.mean_absolute_error(x, y))\n",
    "    },\n",
    "    n_splits=5,\n",
    "    class_name=\"hospitalizedIncrease\",\n",
    "    lin=linear,\n",
    "    dtree=dtree,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Analysis was performed on each model to determine the validity and accuracy of the model, as well as the training time and prediction time.\n",
    "\n",
    "### Runtime\n",
    "\n",
    "* Linear Regression\n",
    "* MLP - Eliminated for runtime constraints.\n",
    "* Decision Tree Regression\n",
    "* SVM Regression - Eliminated for runtime constraints.\n",
    "\n",
    "### Model metrics\n",
    "\n",
    "The linear regression performed the calculation with an RMSE of 6.83, compared to 6.98 of the decision tree implementation.  These two proved the most comparable in terms of accuracy and runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "resdf = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "\n",
    "axes = resdf.plot.bar(rot=0, subplots=True)\n",
    "_ = [print(k,\":\",v) for k,v in results.items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The questions proposed in the introduction are answered below:\n",
    "\n",
    "1. Does this data suffice to train a model that can successfully predict the spread of COVID in an area given the historical data provided?\n",
    "    \n",
    "        Yes, several models were used, several of which trained to make a prediction within the scope of the project.  \n",
    "        Each model was measured by its Mean Absolute Error, Mean Squared Error, and Root Mean Squared Error.\n",
    "\n",
    "2. Can we predict the number of total cases in a given region based on the testing/hospitalization data, state information, and any other categorical parameters included?\n",
    "\n",
    "        Yes, we can accurately predict the number of cases or the increase in a region given state population and growth \n",
    "        and the given testing and hospitalization data.\n",
    "\n",
    "3. Can this model predict certain outcomes based on the pre-processed, daily intake data provided by the API?\n",
    "\n",
    "        Yes, the linear and decision tree model can generate a prediction based on the value from current state data, \n",
    "        as seen below.\n",
    "\n",
    "4. Which method of machine learning can generate the most succesful prediction/model of the coronavirus spread?\n",
    "\n",
    "        A linear regression model most successfuly models the data with the least error, and quickest runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(links['curr_state'])\n",
    "clean_df = generate_df(test_df).fillna(test_df.mean())\n",
    "print(df.columns)\n",
    "print(clean_df.columns)\n",
    "clean_df['lin_pred'] = linear.predict(clean_df.to_numpy())\n",
    "clean_df['dtree_pred'] = dtree.predict(clean_df.to_numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
